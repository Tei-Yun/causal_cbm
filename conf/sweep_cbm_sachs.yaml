defaults:
  - default
  - override causal_discovery: ges
  - override llm: gpt
  - override rag: standard
  - _self_  
  # override this to use the new list sweeper:
  - override hydra/sweeper: list
 
hydra:
  mode: MULTIRUN
  sweep:
    dir: "outputs/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}_cbm_mlp_bn"
  sweeper:
    # standard grid search
    grid_params:
      # possible datsets are:
      # asia, sachs, insurance, alarm, hailfinder, cub_causal_struct, synthetic
      # colormnist, colormnist_ood, celeba, celeba_unfair, siim_pneumothorax
      # possible models are:
      # blackbox, blackbox_multi, cbm_linear, cbm_mlp, cem, c2bm
      model: cbm_mlp
      seed: 1
    # additional list sweeper
    list_params:
      dataset: sachs
      model.hidden_size:      [64]    
      model.concept_loss_weight: [0.8]  
      engine.optim_kwargs.lr: [0.00075]

policy: none #none, levels_true, levels_pred, nodes_true, nodes_pred, random + cnf_int, cnf_cf
cnf_bundle_path: '/home/younsuk/causal_cbm/CNF_notebooks/cnf_bundle.pt'

# Test only mode: set test_only=true and provide checkpoint_path to skip training
test_only: true
checkpoint_path: "/home/younsuk/causal_cbm/outputs/multirun/2025-12-05/15-16-55_cbm_mlp_bn/0/checkpoints/epoch=73-step=1036.ckpt"


dataset:
  load_embeddings: false
  load_graph: false
  load_true_graph: true
  batch_size: 512  # 128 (Pneumo, all SCBM), 512 (all others)
  autoencoder:
    noise: 0.5  # for bndatasets only
  num_workers: 0

engine:
  intervention_prob: 0.8
  test_interv_noise: 0.8   # for bndatasets only

trainer:
  logger: null  # wandb, null
  devices: [0]
  max_epochs: 500
  patience: 30


# rag:
#   verbose: false
#   source: arxiv # arxiv or custom (arxiv + www scraper)

notes: neurips_test