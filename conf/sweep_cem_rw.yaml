defaults:
  - default
  #tei 주석 처리 11/29
  #- override causal_discovery: ges
  #- override llm: gpt
  #- override rag: standard
  - override causal_discovery: Null
  - override llm: Null
  - override rag: Null
  - _self_  
  # override this to use the new list sweeper:
  - override hydra/sweeper: list
 
hydra:
  mode: MULTIRUN
  sweep:
    dir: "outputs/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}_cem_real"
  sweeper:
    # standard grid search
    grid_params:
      # possible datsets are:
      # asia, sachs, insurance, alarm, hailfinder, cub_causal_struct, synthetic
      # colormnist, colormnist_ood, celeba, celeba_unfair, siim_pneumothorax
      # possible models are:
      # blackbox, blackbox_multi, cbm_linear, cbm_mlp, cem, c2bm
      model: cem
      seed: 1,2,3,4,5
      model.hidden_size: 64   
      model.concept_loss_weight: 0.8
      model.concept_hidden_size: 4
      model.dropout: 0.5
      engine.optim_kwargs.lr: 0.00075
    list_params:
      dataset: celeba #, cub_causal_struct, siim_pneumothorax
      dataset.batch_size: 512 #, 512, 128

policy: nodes_true # levels_true, levels_pred, nodes_true, nodes_pred, random

dataset:
  #load_embeddings: false
  load_embeddings: true
  load_graph: true        # <--- 여기를 true로 변경 (저장된 graph.pkl 로드)
  load_true_graph: false  # <--- 여기는 false 유지 (코드 상의 True Graph 사용 안 함)
  # batch_size: 512  # 128 (Pneumo, all SCBM), 512 (all others)
  num_workers: 0

engine:
  intervention_prob: 0.8

trainer:
  logger: wandb   # wandb, null
  devices: [2]
  max_epochs: 500
  patience: 30

#tei 수정 11/29
# [Add] WandB 설정 추가
logger:
  wandb:
    project: "cem_rw"  # 프로젝트 이름
    name: "cem_celeba_run"     # 실행 이름 (옵션)
    group: "experiment_group_1" # 그룹 이름 (옵션)


#tei 수정 11/29
#이 부분이 살아있어서 위쪽의 Null 설정을 덮어쓰고 있었음
# rag:
#   verbose: false
#   source: arxiv # arxiv or custom (arxiv + www scraper)


notes: neurips_test